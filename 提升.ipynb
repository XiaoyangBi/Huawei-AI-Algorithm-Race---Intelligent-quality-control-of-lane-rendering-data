{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fdc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装相关依赖库 如果是windows系统，cmd命令框中输入pip安装，或在Jupyter notebook中!pip安装，参考上述环境配置\n",
    "#!pip install pandas numpy cv2 torch torchvision codecs PIL glob\n",
    "#---------------------------------------------------\n",
    "#导入库\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import csv, time\n",
    "import numpy as np\n",
    "\n",
    "# pytorch相关\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411e0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义读取数据集\n",
    "class ImageSet(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            images,\n",
    "            labels,\n",
    "            transform):\n",
    "        self.transform = transform\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        imagename = self.images[item]\n",
    "        \n",
    "        # 防止文件出错，这里生成一个随机的照片\n",
    "        try:\n",
    "            image = Image.open(imagename)\n",
    "            image = image.convert('RGB')\n",
    "        except:\n",
    "            image = Image.fromarray(np.zeros((256, 256), dtype=np.int8))\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        image = self.transform(image)\n",
    "        return image, torch.tensor(self.labels[item])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0125112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "# 训练集标注数据\n",
    "lines = codecs.open('train_label.csv').readlines()\n",
    "train_label = pd.DataFrame({\n",
    "    'image': ['train_image/' + x.strip().split(',')[0] for x in lines],\n",
    "    'label': [x.strip().split(',')[1:] for x in lines],\n",
    "})\n",
    "\n",
    "# 将标签进行二值化处理\n",
    "train_label['new_label'] = train_label['label'].apply(lambda x: int('0' in x))\n",
    "\n",
    "# 数据扩增方法\n",
    "trfs = transforms.Compose([\n",
    "    A.RandomCrop(450, 750),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    A.CoarseDropout(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 训练集dataset和dataloder\n",
    "# 这里我们使用前1000张图片进行训练，后续可以自行修改\n",
    "train_dataset = ImageSet(train_label['image'].values,\n",
    "                         train_label['new_label'].values,\n",
    "                         trfs)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# 测试集dataset和dataloder\n",
    "test_images = glob.glob('./test_images/*')\n",
    "test_dataset = ImageSet(test_images, [0] * len(test_images), trfs)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fcd9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "unlabeled_set = DatasetFolder(r\"C:\\Users\\BiXY\\OneDrive - 厦门大学(马来西亚分校)\\竞赛\\华为AI算法赛\\digix-2022-cv-sample\\digix-2022-cv-sample\\train_image\\unlabeled_data\", loader=lambda x: Image.open(x).convert('RGB'), extensions=\"png\", transform=trfs)\n",
    "\n",
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.label = y\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        return self.data[idx][0], torch.tensor(self.label[idx])\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def get_pseudo_labels(dataset, model, threshold=0.65):\n",
    "    # This functions generates pseudo-labels of a dataset using given model.\n",
    "    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n",
    "    # You are NOT allowed to use any models trained on external data for pseudo-labeling.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Construct a data loader.\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Make sure the model is in eval mode.\n",
    "    model.eval()\n",
    "    # Define softmax function.\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    # Iterate over the dataset by batches.\n",
    "    new_sample = []\n",
    "    new_label = []\n",
    "    #i = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        img, _ = batch\n",
    "        #print(\"****img:\",img.shape)\n",
    "        # Forward the data\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(img.to(device))\n",
    "\n",
    "        # Obtain the probability distributions by applying softmax on logits.\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        # ---------- TODO ----------\n",
    "        # Filter the data and construct a new dataset.\n",
    "        probs_argmax = probs.argmax(dim=-1).cpu().numpy().tolist()\n",
    "        probs_max = probs.max(dim=-1).values\n",
    "        probs_max = probs_max.cpu().numpy().tolist()\n",
    "        #feat = []\n",
    "        i = 0\n",
    "        for idx,p in enumerate(probs_max):\n",
    "            if p > threshold:\n",
    "                new_sample.append(idx + i * batch_size)\n",
    "                new_label.append(probs_argmax[idx])\n",
    "        i = i + 1\n",
    "    new_data = Subset(dataset,new_sample)          \n",
    "    new_label_set = PseudoDataset(new_data,new_label)\n",
    "    # # Turn off the eval mode.\n",
    "    model.train()\n",
    "    return new_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513b6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "train_dataset = ImageSet(train_label['image'].values,\n",
    "                         train_label['new_label'].values,\n",
    "                         trfs)\n",
    "print(train_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f44521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        \"\"\"Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        # 此处的self.smoothing即我们的epsilon平滑参数。\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a562d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1036/1036 [1:43:37<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35695362091064453 0 4013\n",
      "0.3913387060165405 10 4013\n",
      "0.22286942601203918 20 4013\n",
      "0.21221011877059937 30 4013\n",
      "0.21745653450489044 40 4013\n",
      "0.21446934342384338 50 4013\n",
      "0.26699262857437134 60 4013\n",
      "0.2683424949645996 70 4013\n",
      "0.2088620662689209 80 4013\n",
      "0.3177863359451294 90 4013\n",
      "0.2615867853164673 100 4013\n",
      "0.21865057945251465 110 4013\n",
      "0.21652933955192566 120 4013\n",
      "0.26618847250938416 130 4013\n",
      "0.30943745374679565 140 4013\n",
      "0.2704204022884369 150 4013\n",
      "0.26976990699768066 160 4013\n",
      "0.21105660498142242 170 4013\n",
      "0.25849518179893494 180 4013\n",
      "0.2205537110567093 190 4013\n",
      "0.2593487501144409 200 4013\n",
      "0.3708856701850891 210 4013\n",
      "0.31158629059791565 220 4013\n",
      "0.26527106761932373 230 4013\n",
      "0.2506088614463806 240 4013\n",
      "0.2627578377723694 250 4013\n",
      "0.21094045042991638 260 4013\n",
      "0.2273663878440857 270 4013\n",
      "0.2091745138168335 280 4013\n",
      "0.20608395338058472 290 4013\n",
      "0.2605726718902588 300 4013\n",
      "0.20600956678390503 310 4013\n",
      "0.21832594275474548 320 4013\n",
      "0.20664499700069427 330 4013\n",
      "0.35769402980804443 340 4013\n",
      "0.21110926568508148 350 4013\n",
      "0.205860435962677 360 4013\n",
      "0.3577660918235779 370 4013\n",
      "0.21591201424598694 380 4013\n",
      "0.2101152539253235 390 4013\n",
      "0.30845654010772705 400 4013\n",
      "0.21278047561645508 410 4013\n",
      "0.21175912022590637 420 4013\n",
      "0.22661006450653076 430 4013\n",
      "0.26363658905029297 440 4013\n",
      "0.26220589876174927 450 4013\n",
      "0.2874397933483124 460 4013\n",
      "0.26928094029426575 470 4013\n",
      "0.30764737725257874 480 4013\n",
      "0.25355643033981323 490 4013\n",
      "0.3061314821243286 500 4013\n",
      "0.21586264669895172 510 4013\n",
      "0.261430948972702 520 4013\n",
      "0.2109905481338501 530 4013\n",
      "0.2162923812866211 540 4013\n",
      "0.2607197165489197 550 4013\n",
      "0.3561859726905823 560 4013\n",
      "0.21089589595794678 570 4013\n",
      "0.3588227927684784 580 4013\n",
      "0.3191753625869751 590 4013\n",
      "0.3728044033050537 600 4013\n",
      "0.2543692886829376 610 4013\n",
      "0.2629896402359009 620 4013\n",
      "0.20929154753684998 630 4013\n",
      "0.25779813528060913 640 4013\n",
      "0.26004379987716675 650 4013\n",
      "0.26105791330337524 660 4013\n",
      "0.20814791321754456 670 4013\n",
      "0.2782323360443115 680 4013\n",
      "0.2580309510231018 690 4013\n",
      "0.3073360323905945 700 4013\n",
      "0.2535610795021057 710 4013\n",
      "0.2232944667339325 720 4013\n",
      "0.25694355368614197 730 4013\n",
      "0.22233980894088745 740 4013\n",
      "0.26302793622016907 750 4013\n",
      "0.31104639172554016 760 4013\n",
      "0.21359556913375854 770 4013\n",
      "0.2569066286087036 780 4013\n",
      "0.31708064675331116 790 4013\n",
      "0.20830808579921722 800 4013\n",
      "0.3148503601551056 810 4013\n",
      "0.259376585483551 820 4013\n",
      "0.21026411652565002 830 4013\n",
      "0.2600615918636322 840 4013\n",
      "0.22168689966201782 850 4013\n",
      "0.2877959907054901 860 4013\n",
      "0.25673386454582214 870 4013\n",
      "0.21521824598312378 880 4013\n",
      "0.2990344762802124 890 4013\n",
      "0.2100660502910614 900 4013\n",
      "0.2517101466655731 910 4013\n",
      "0.21539103984832764 920 4013\n",
      "0.25944626331329346 930 4013\n",
      "0.3133138418197632 940 4013\n",
      "0.20861384272575378 950 4013\n",
      "0.25485265254974365 960 4013\n",
      "0.20757654309272766 970 4013\n",
      "0.2079211324453354 980 4013\n",
      "0.26018089056015015 990 4013\n",
      "0.2165529727935791 1000 4013\n",
      "0.21512627601623535 1010 4013\n",
      "0.25711095333099365 1020 4013\n",
      "0.21527546644210815 1030 4013\n",
      "0.2196471393108368 1040 4013\n",
      "0.26218780875205994 1050 4013\n",
      "0.35943326354026794 1060 4013\n",
      "0.21039792895317078 1070 4013\n",
      "0.26382195949554443 1080 4013\n",
      "0.2599083185195923 1090 4013\n",
      "0.29569298028945923 1100 4013\n",
      "0.2617519199848175 1110 4013\n",
      "0.3208090662956238 1120 4013\n",
      "0.3150867223739624 1130 4013\n",
      "0.32244911789894104 1140 4013\n",
      "0.30848199129104614 1150 4013\n",
      "0.25308388471603394 1160 4013\n",
      "0.31430262327194214 1170 4013\n",
      "0.262297660112381 1180 4013\n",
      "0.26500260829925537 1190 4013\n",
      "0.34752434492111206 1200 4013\n",
      "0.2566390633583069 1210 4013\n",
      "0.2574099004268646 1220 4013\n",
      "0.26249194145202637 1230 4013\n",
      "0.21168924868106842 1240 4013\n",
      "0.2136874794960022 1250 4013\n",
      "0.3067050874233246 1260 4013\n",
      "0.29798024892807007 1270 4013\n",
      "0.22043246030807495 1280 4013\n",
      "0.21358071267604828 1290 4013\n",
      "0.36603492498397827 1300 4013\n",
      "0.2131531834602356 1310 4013\n",
      "0.3181852400302887 1320 4013\n",
      "0.31241947412490845 1330 4013\n",
      "0.2602795660495758 1340 4013\n",
      "0.305673211812973 1350 4013\n",
      "0.30438584089279175 1360 4013\n",
      "0.2583199143409729 1370 4013\n",
      "0.20976993441581726 1380 4013\n",
      "0.2728254199028015 1390 4013\n",
      "0.26235294342041016 1400 4013\n",
      "0.26286154985427856 1410 4013\n",
      "0.25949907302856445 1420 4013\n",
      "0.31557899713516235 1430 4013\n",
      "0.209956094622612 1440 4013\n",
      "0.21713313460350037 1450 4013\n",
      "0.2574653625488281 1460 4013\n",
      "0.2113066464662552 1470 4013\n",
      "0.2611827850341797 1480 4013\n",
      "0.20662975311279297 1490 4013\n",
      "0.2077496200799942 1500 4013\n",
      "0.26286959648132324 1510 4013\n",
      "0.26390981674194336 1520 4013\n",
      "0.2025594413280487 1530 4013\n",
      "0.366388201713562 1540 4013\n",
      "0.25807806849479675 1550 4013\n",
      "0.21197566390037537 1560 4013\n",
      "0.205300435423851 1570 4013\n",
      "0.2624903917312622 1580 4013\n",
      "0.20563390851020813 1590 4013\n",
      "0.2069908082485199 1600 4013\n",
      "0.2604939937591553 1610 4013\n",
      "0.20659786462783813 1620 4013\n",
      "0.20881155133247375 1630 4013\n",
      "0.2608710527420044 1640 4013\n",
      "0.2066599726676941 1650 4013\n",
      "0.3161047399044037 1660 4013\n",
      "0.20823082327842712 1670 4013\n",
      "0.20584005117416382 1680 4013\n",
      "0.35434865951538086 1690 4013\n",
      "0.20691639184951782 1700 4013\n",
      "0.2596970200538635 1710 4013\n",
      "0.26357436180114746 1720 4013\n",
      "0.213079035282135 1730 4013\n",
      "0.2599177956581116 1740 4013\n",
      "0.20467564463615417 1750 4013\n",
      "0.21172484755516052 1760 4013\n",
      "0.3590763211250305 1770 4013\n",
      "0.2077690064907074 1780 4013\n",
      "0.26250556111335754 1790 4013\n",
      "0.20464932918548584 1800 4013\n",
      "0.2615964114665985 1810 4013\n",
      "0.20741750299930573 1820 4013\n",
      "0.2642827033996582 1830 4013\n",
      "0.37802791595458984 1840 4013\n",
      "0.31198644638061523 1850 4013\n",
      "0.20715969800949097 1860 4013\n",
      "0.20781758427619934 1870 4013\n",
      "0.2595214247703552 1880 4013\n",
      "0.25625813007354736 1890 4013\n",
      "0.21197910606861115 1900 4013\n",
      "0.2587448060512543 1910 4013\n",
      "0.2604207396507263 1920 4013\n",
      "0.20903943479061127 1930 4013\n",
      "0.2603219151496887 1940 4013\n",
      "0.2111591100692749 1950 4013\n",
      "0.252940833568573 1960 4013\n",
      "0.2592660188674927 1970 4013\n",
      "0.21495972573757172 1980 4013\n",
      "0.2626902461051941 1990 4013\n",
      "0.26152029633522034 2000 4013\n",
      "0.3121042847633362 2010 4013\n",
      "0.26416656374931335 2020 4013\n",
      "0.25340166687965393 2030 4013\n",
      "0.34522128105163574 2040 4013\n",
      "0.2137068659067154 2050 4013\n",
      "0.34742483496665955 2060 4013\n",
      "0.3164540231227875 2070 4013\n",
      "0.21346697211265564 2080 4013\n",
      "0.26876991987228394 2090 4013\n",
      "0.2985527217388153 2100 4013\n",
      "0.31077539920806885 2110 4013\n",
      "0.2135985791683197 2120 4013\n",
      "0.2977202832698822 2130 4013\n",
      "0.31065523624420166 2140 4013\n",
      "0.319261372089386 2150 4013\n",
      "0.20785672962665558 2160 4013\n",
      "0.2638206481933594 2170 4013\n",
      "0.3141253590583801 2180 4013\n",
      "0.2541455626487732 2190 4013\n",
      "0.21191182732582092 2200 4013\n",
      "0.22234949469566345 2210 4013\n",
      "0.2107568234205246 2220 4013\n",
      "0.2605063319206238 2230 4013\n",
      "0.3070051372051239 2240 4013\n",
      "0.25482863187789917 2250 4013\n",
      "0.2565005123615265 2260 4013\n",
      "0.2648860812187195 2270 4013\n",
      "0.2507413625717163 2280 4013\n",
      "0.2060786634683609 2290 4013\n",
      "0.2093433439731598 2300 4013\n",
      "0.3005579113960266 2310 4013\n",
      "0.3006420135498047 2320 4013\n",
      "0.2987801730632782 2330 4013\n",
      "0.216645747423172 2340 4013\n",
      "0.2602233588695526 2350 4013\n",
      "0.21344323456287384 2360 4013\n",
      "0.20994062721729279 2370 4013\n",
      "0.21180911362171173 2380 4013\n",
      "0.2111649215221405 2390 4013\n",
      "0.34333741664886475 2400 4013\n",
      "0.21718421578407288 2410 4013\n",
      "0.2153509557247162 2420 4013\n",
      "0.20950806140899658 2430 4013\n",
      "0.2603456974029541 2440 4013\n",
      "0.21018220484256744 2450 4013\n",
      "0.20652037858963013 2460 4013\n",
      "0.3116532564163208 2470 4013\n",
      "0.21622596681118011 2480 4013\n",
      "0.260148286819458 2490 4013\n",
      "0.2124691903591156 2500 4013\n",
      "0.26581478118896484 2510 4013\n",
      "0.20592007040977478 2520 4013\n",
      "0.20653939247131348 2530 4013\n",
      "0.3634262681007385 2540 4013\n",
      "0.34515124559402466 2550 4013\n",
      "0.3918486535549164 2560 4013\n",
      "0.21506360173225403 2570 4013\n",
      "0.3763638734817505 2580 4013\n",
      "0.25476691126823425 2590 4013\n",
      "0.21032975614070892 2600 4013\n",
      "0.26426106691360474 2610 4013\n",
      "0.2136482447385788 2620 4013\n",
      "0.20574937760829926 2630 4013\n",
      "0.21191652119159698 2640 4013\n",
      "0.21115455031394958 2650 4013\n",
      "0.2109842300415039 2660 4013\n",
      "0.25661131739616394 2670 4013\n",
      "0.25584688782691956 2680 4013\n",
      "0.3062184453010559 2690 4013\n",
      "0.2130516767501831 2700 4013\n",
      "0.2587360143661499 2710 4013\n",
      "0.21570603549480438 2720 4013\n",
      "0.21116231381893158 2730 4013\n",
      "0.3446359932422638 2740 4013\n",
      "0.26360851526260376 2750 4013\n",
      "0.2621350586414337 2760 4013\n",
      "0.21537688374519348 2770 4013\n",
      "0.20907601714134216 2780 4013\n",
      "0.2620844841003418 2790 4013\n",
      "0.2204442173242569 2800 4013\n",
      "0.26639795303344727 2810 4013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22025105357170105 2820 4013\n",
      "0.2557830810546875 2830 4013\n",
      "0.2564833164215088 2840 4013\n",
      "0.20998087525367737 2850 4013\n",
      "0.2604927718639374 2860 4013\n",
      "0.2596915364265442 2870 4013\n",
      "0.21062573790550232 2880 4013\n",
      "0.2114545702934265 2890 4013\n",
      "0.3687609136104584 2900 4013\n",
      "0.26283690333366394 2910 4013\n",
      "0.25771141052246094 2920 4013\n",
      "0.3140549659729004 2930 4013\n",
      "0.26895833015441895 2940 4013\n",
      "0.20522922277450562 2950 4013\n",
      "0.3762352764606476 2960 4013\n",
      "0.30571043491363525 2970 4013\n",
      "0.26241540908813477 2980 4013\n",
      "0.20565734803676605 2990 4013\n",
      "0.20458991825580597 3000 4013\n",
      "0.20450067520141602 3010 4013\n",
      "0.260669469833374 3020 4013\n",
      "0.2075699269771576 3030 4013\n",
      "0.3108227550983429 3040 4013\n",
      "0.2082522064447403 3050 4013\n",
      "0.20517602562904358 3060 4013\n",
      "0.31860530376434326 3070 4013\n",
      "0.25850751996040344 3080 4013\n",
      "0.3132564127445221 3090 4013\n",
      "0.2583811581134796 3100 4013\n",
      "0.2620445787906647 3110 4013\n",
      "0.3906550407409668 3120 4013\n",
      "0.25535768270492554 3130 4013\n",
      "0.20776313543319702 3140 4013\n",
      "0.21002864837646484 3150 4013\n",
      "0.2088831067085266 3160 4013\n",
      "0.3653261363506317 3170 4013\n",
      "0.2593795657157898 3180 4013\n",
      "0.2575867176055908 3190 4013\n",
      "0.2610742747783661 3200 4013\n",
      "0.2059617042541504 3210 4013\n",
      "0.25839489698410034 3220 4013\n",
      "0.2621143162250519 3230 4013\n",
      "0.27882713079452515 3240 4013\n",
      "0.26367026567459106 3250 4013\n",
      "0.25165432691574097 3260 4013\n",
      "0.3037264049053192 3270 4013\n",
      "0.35329437255859375 3280 4013\n",
      "0.20629161596298218 3290 4013\n",
      "0.20731106400489807 3300 4013\n",
      "0.20714114606380463 3310 4013\n",
      "0.21643194556236267 3320 4013\n",
      "0.20888033509254456 3330 4013\n",
      "0.2568744122982025 3340 4013\n",
      "0.3072200119495392 3350 4013\n",
      "0.21261613070964813 3360 4013\n",
      "0.2580944299697876 3370 4013\n",
      "0.299594521522522 3380 4013\n",
      "0.21168245375156403 3390 4013\n",
      "0.26029789447784424 3400 4013\n",
      "0.20833057165145874 3410 4013\n",
      "0.20524883270263672 3420 4013\n",
      "0.2093149870634079 3430 4013\n",
      "0.31403306126594543 3440 4013\n",
      "0.20522847771644592 3450 4013\n",
      "0.20831623673439026 3460 4013\n",
      "0.2565576434135437 3470 4013\n",
      "0.21494731307029724 3480 4013\n",
      "0.2579984962940216 3490 4013\n",
      "0.2114337682723999 3500 4013\n",
      "0.37275004386901855 3510 4013\n",
      "0.30729877948760986 3520 4013\n",
      "0.2602574825286865 3530 4013\n",
      "0.31068021059036255 3540 4013\n",
      "0.21265220642089844 3550 4013\n",
      "0.20450633764266968 3560 4013\n",
      "0.2582685351371765 3570 4013\n",
      "0.2704997658729553 3580 4013\n",
      "0.31149688363075256 3590 4013\n",
      "0.40366923809051514 3600 4013\n",
      "0.2139246165752411 3610 4013\n",
      "0.3103174567222595 3620 4013\n",
      "0.20627711713314056 3630 4013\n",
      "0.26039785146713257 3640 4013\n",
      "0.20665544271469116 3650 4013\n",
      "0.25463634729385376 3660 4013\n",
      "0.2061786651611328 3670 4013\n",
      "0.2072947472333908 3680 4013\n",
      "0.26787373423576355 3690 4013\n",
      "0.2568050026893616 3700 4013\n",
      "0.31212177872657776 3710 4013\n",
      "0.20566490292549133 3720 4013\n",
      "0.2645930051803589 3730 4013\n",
      "0.3047824501991272 3740 4013\n",
      "0.211356520652771 3750 4013\n",
      "0.41679760813713074 3760 4013\n",
      "0.2071095108985901 3770 4013\n",
      "0.2664637565612793 3780 4013\n",
      "0.36680954694747925 3790 4013\n",
      "0.3095182180404663 3800 4013\n",
      "0.26034611463546753 3810 4013\n",
      "0.21149194240570068 3820 4013\n",
      "0.2547546327114105 3830 4013\n",
      "0.20812273025512695 3840 4013\n",
      "0.306729793548584 3850 4013\n",
      "0.26213526725769043 3860 4013\n",
      "0.2581968903541565 3870 4013\n",
      "0.26198625564575195 3880 4013\n",
      "0.21014386415481567 3890 4013\n",
      "0.22352886199951172 3900 4013\n",
      "0.25578221678733826 3910 4013\n",
      "0.2585602104663849 3920 4013\n",
      "0.2601829171180725 3930 4013\n",
      "0.2100580781698227 3940 4013\n",
      "0.26235800981521606 3950 4013\n",
      "0.311428964138031 3960 4013\n",
      "0.20681679248809814 3970 4013\n",
      "0.3027522563934326 3980 4013\n",
      "0.25751757621765137 3990 4013\n",
      "0.2589770555496216 4000 4013\n",
      "0.21258673071861267 4010 4013\n",
      "...epoch:   1/  2, loss: 0.2540, average time: 3.06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▋                                        | 508/1036 [55:07<57:36,  6.55s/it]"
     ]
    }
   ],
   "source": [
    "# 加载resnet18预训练模型\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to('cuda') #使用GPU\n",
    "\n",
    "# 模型优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# 模型损失函数\n",
    "loss = LabelSmoothing(smoothing=0.1)\n",
    "\n",
    "# 接下来我们使用pytorch完成模型的训练：\n",
    "# Python\n",
    "# 设置迭代轮数epochs，可调整，轮数越多，所花时间越久\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    start_t = time.time()\n",
    "    epoch_l = 0\n",
    "    epoch_t = 0\n",
    "    pseudo_set = get_pseudo_labels(unlabeled_set, model)\n",
    "\n",
    "    # Construct a new dataset and a data loader for training.\n",
    "    # This is used in semi-supervised learning only.\n",
    "    concat_dataset = ConcatDataset([train_dataset, pseudo_set])\n",
    "    train_loader = DataLoader(concat_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    \n",
    "    # 批量训练\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        image, label = batch\n",
    "        image, label = image.to('cuda'), label.to('cuda')\n",
    "        output = model(image) # 正向传播\n",
    "\n",
    "        l = loss(output, label) # 计算损失\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_l = l.item()\n",
    "        epoch_l += batch_l\n",
    "        batch_t = time.time() - start_t\n",
    "        epoch_t += batch_t\n",
    "        start_t = time.time()\n",
    "        \n",
    "        # 打印loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(l.item(), batch_idx, len(train_loader))\n",
    "\n",
    "    epoch_t = epoch_t / len(train_loader)\n",
    "    epoch_l = epoch_l / len(train_loader)\n",
    "    print('...epoch: {:3d}/{:3d}, loss: {:.4f}, average time: {:.2f}.'.format(\n",
    "        epoch + 1, epochs, epoch_l, epoch_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f36cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "to_prob = nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    imagenames, probs = list(), list()\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        image, _ = batch\n",
    "        image = image.to('cuda')\n",
    "        pred = model(image)\n",
    "        prob = to_prob(pred)\n",
    "        prob = list(prob.data.cpu().numpy())\n",
    "        probs += prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('submission.csv', 'w',newline = '', encoding='utf8') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(['imagename', 'defect_prob'])\n",
    "    for imagename, prob in zip(test_images, probs):\n",
    "        imagename = os.path.basename(imagename)\n",
    "        writer.writerow([imagename, str(prob[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a9977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
